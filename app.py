import streamlit as st
import pandas as pd
import json
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed

# å¯¼å…¥ç°æœ‰åç«¯æ¨¡å—
import okx_api_client
import ai_client
import arkham_client
import ai_conclusion
from okx_api_client import get_transactions_by_address, get_transaction_detail_by_hash
from data_processor import extract_tx_info_from_summary, process_and_clean_details
from ai_client import analyze_transaction
from arkham_client import get_arkham_intelligence
from ai_conclusion import generate_conclusion, chat_with_report
from db_manager import (
    get_transaction_details_by_hashes, add_transaction_detail, 
    get_labels_by_addresses, add_labels, update_ai_analysis,
    setup_databases, list_available_chats, load_chat_session,
    reset_chat_history
)

# ========== é¡µé¢é…ç½® ==========
st.set_page_config(
    page_title="AI é“¾ä¸Šä¾¦æ¢",
    page_icon="ğŸ•µï¸â€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========== å…¨å±€å¸¸é‡ï¼šé“¾é…ç½® ==========
CHAIN_MAP = {
    # EVM é“¾
    "1": "Ethereum Mainnet (ETH)",
    "56": "BNB Smart Chain (BSC)",
    "137": "Polygon Mainnet",
    "42161": "Arbitrum One",
    "10": "OP Mainnet",
    "8453": "Base",
    "59144": "Linea",
    "324": "zkSync Era",
    "43114": "Avalanche C-Chain",
    "196": "X layer",
    "1101": "Polygon zkEVM",
    "146": "Sonic",
    "130": "Uni Chain",
    "250": "Fantom Opera",
    "5000": "Mantle",
    "1030": "Conflux eSpace",
    "1088": "Metis Andromeda",
    "4200": "Merlin Chain",
    "81457": "Blast",
    "169": "Manta Pacific",
    "534352": "Scroll",
    "25": "Cronos Mainnet",
    "7000": "ZetaChain",
    "9745": "Plasma",
    "143": "Monad",
    # é EVM é“¾
    "195": "Tron",
    "501": "Solana",
    "784": "SUI",
    "607": "Ton"
}

SORTED_CHAIN_IDS = ["1", "56", "137", "42161", "10", "195", "501"] + sorted(
    [k for k in CHAIN_MAP.keys() if k not in ["1", "56", "137", "42161", "10", "195", "501"]],
    key=lambda x: CHAIN_MAP[x]
)

# ========== CSS ç¾åŒ– ==========
st.markdown("""
<style>
    .report-text {
        font-family: 'Helvetica Neue', sans-serif;
        line-height: 1.6;
        color: #e0e0e0;
    }
    .stButton>button {
        width: 100%;
        border-radius: 20px;
        background-color: #FF4B4B;
        color: white;
    }
    .highlight-box {
        padding: 20px;
        background-color: #262730;
        border-radius: 10px;
        border-left: 5px solid #FF4B4B;
        margin-bottom: 20px;
    }
    .stChatInput {
        padding-bottom: 20px;
    }
</style>
""", unsafe_allow_html=True)

# ========== è‡ªåŠ¨é…ç½®åŠ è½½ (Monkey Patch) ==========
try:
    if "OPENROUTER_API_KEY" in st.secrets:
        ai_client.API_KEY = st.secrets["OPENROUTER_API_KEY"]
        ai_conclusion.API_KEY = st.secrets["OPENROUTER_API_KEY"]
    
    if "OKX_API_KEY" in st.secrets:
        okx_api_client.API_KEY = st.secrets["OKX_API_KEY"]
        okx_api_client.SECRET_KEY = st.secrets["OKX_SECRET_KEY"]
        okx_api_client.PASSPHRASE = st.secrets["OKX_PASSPHRASE"]
        
    if "APIFY_API_TOKEN" in st.secrets:
        from apify_client import ApifyClient
        arkham_client.APIFY_API_TOKEN = st.secrets["APIFY_API_TOKEN"]
        arkham_client.client = ApifyClient(st.secrets["APIFY_API_TOKEN"])
except FileNotFoundError:
    pass

# ========== Session State åˆå§‹åŒ– ==========
if "messages" not in st.session_state:
    st.session_state.messages = []
if "analysis_done" not in st.session_state:
    st.session_state.analysis_done = False
if "report_content" not in st.session_state:
    st.session_state.report_content = ""
if "analyses_summary" not in st.session_state:
    st.session_state.analyses_summary = ""
if "processed_txs" not in st.session_state:
    st.session_state.processed_txs = []
if "current_address" not in st.session_state:
    st.session_state.current_address = ""

# åˆå§‹åŒ–æ•°æ®åº“ï¼ˆç¡®ä¿ç›®å½•å­˜åœ¨ï¼‰
setup_databases()

# ========== ä¾§è¾¹æ  ==========
with st.sidebar:
    st.title("ğŸ•µï¸â€â™‚ï¸ é…ç½®ä¸­å¿ƒ")
    
    # --- å†å²è®°å½•åŠŸèƒ½ ---
    st.markdown("### ğŸ“‚ å†å²æ¡£æ¡ˆ")
    available_chats = list_available_chats()
    
    # å¢åŠ ä¸€ä¸ª "è¯·é€‰æ‹©" çš„é»˜è®¤é€‰é¡¹
    history_options = ["è¯·é€‰æ‹©..."] + available_chats
    
    selected_history = st.selectbox(
        "æ¢å¤ä¹‹å‰çš„è°ƒæŸ¥",
        options=history_options,
        index=0,
        help="é€‰æ‹©ä¸€ä¸ªåœ°å€ä»¥æ¢å¤ä¹‹å‰çš„åˆ†ææŠ¥å‘Šå’Œå¯¹è¯è®°å½•"
    )
    
    # å¦‚æœç”¨æˆ·é€‰æ‹©äº†æŸä¸ªå†å²è®°å½•ï¼Œä¸”è·Ÿå½“å‰æ˜¾ç¤ºçš„ä¸ä»…ä»…æ˜¯åŒä¸€ä¸ª
    if selected_history != "è¯·é€‰æ‹©..." and selected_history != st.session_state.current_address:
        if st.button("ğŸ“¥ åŠ è½½æ¡£æ¡ˆ"):
            try:
                with st.spinner(f"æ­£åœ¨è¯»å– {selected_history} çš„æ¡£æ¡ˆ..."):
                    report, analyses_summary, history = load_chat_session(selected_history)
                    
                    # æ¢å¤çŠ¶æ€
                    st.session_state.report_content = report
                    st.session_state.analyses_summary = analyses_summary
                    st.session_state.current_address = selected_history
                    st.session_state.analysis_done = True
                    st.session_state.processed_txs = [] # å†å²è®°å½•æš‚ä¸æ¢å¤åŸå§‹äº¤æ˜“è¯¦æƒ…
                    
                    # æ¢å¤å¯¹è¯å†å²
                    restored_msgs = []
                    for msg in history:
                        role = "assistant" if msg['role'] == "assistant" else "user"
                        restored_msgs.append({"role": role, "content": msg['content']})
                    
                    st.session_state.messages = restored_msgs
                    
                    # å¦‚æœæ²¡æœ‰å†å²æ¶ˆæ¯ï¼Œæ·»åŠ é»˜è®¤æ¬¢è¿è¯­
                    if not st.session_state.messages:
                         st.session_state.messages = [{"role": "assistant", "content": "å†å²æ¡£æ¡ˆåŠ è½½å®Œæ¯•ã€‚æ‚¨å¯ä»¥ç»§ç»­å¯¹è¯¥åœ°å€è¿›è¡Œæé—®ã€‚"}]
                    
                    st.success("æ¡£æ¡ˆåŠ è½½æˆåŠŸï¼")
                    time.sleep(0.5)
                    st.rerun()
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {str(e)}")

    st.markdown("---")
    
    # --- æ–°åˆ†æé…ç½® ---
    st.markdown("### ğŸ¯ æ–°ä»»åŠ¡è®¾ç½®")
    
    target_chain = st.selectbox(
        "é€‰æ‹©åŒºå—é“¾",
        options=SORTED_CHAIN_IDS,
        format_func=lambda x: CHAIN_MAP.get(x, f"Unknown ({x})")
    )
    
    tx_limit = st.slider("åˆ†æäº¤æ˜“æ•°é‡", min_value=5, max_value=50, value=10, step=5)
    
    debug_mode = st.checkbox("ğŸªµ æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼ˆOKX/Arkham è°ƒç”¨é—®é¢˜æ’æŸ¥ï¼‰", value=False)
    
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰ä¼šè¯"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# ========== ä¸»ç•Œé¢ ==========
st.title("AI é“¾ä¸Šè¡Œä¸ºåˆ†æå™¨")

# åœ°å€è¾“å…¥åŒº
if not st.session_state.analysis_done:
    st.markdown("è¾“å…¥ä»»ä½•é’±åŒ…åœ°å€ï¼ŒAI å°†ä¸ºæ‚¨ç”Ÿæˆæ·±åº¦è¡Œä¸ºç”»åƒã€èµ„é‡‘æµå‘åˆ†æä»¥åŠé£é™©è¯„ä¼°ã€‚")
    col1, col2 = st.columns([3, 1])
    with col1:
        target_address = st.text_input("é’±åŒ…åœ°å€", placeholder="ä¾‹å¦‚: 0x1234...", key="addr_input")
    with col2:
        st.write("") 
        st.write("")
        start_btn = st.button("ğŸš€ å¼€å§‹ä¾¦æŸ¥")
else:
    st.caption(f"å½“å‰è°ƒæŸ¥ç›®æ ‡: `{st.session_state.current_address}`")
    if st.button("ğŸ” è°ƒæŸ¥æ–°åœ°å€"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()
    start_btn = False

# ========== æ ¸å¿ƒåˆ†æé€»è¾‘ ==========
if start_btn and target_address:
    if len(target_address) < 10:
        st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„é’±åŒ…åœ°å€ï¼")
    else:
        status_container = st.container()
        progress_bar = st.progress(0)
        
        with status_container:
            st.info(f"æ­£åœ¨å¯åŠ¨åˆ†æå¼•æ“... ç›®æ ‡: {target_address} ({CHAIN_MAP.get(target_chain)})")
            
            try:
                # å…³é”®ä¿®å¤ï¼šå¦‚æœæ˜¯æ–°åˆ†æï¼Œå…ˆæ¸…ç©ºè¯¥åœ°å€çš„æ—§èŠå¤©è®°å½•
                # é¿å…æ–°æŠ¥å‘Šç”Ÿæˆåï¼Œä¸‹é¢è¿˜æŒ‚ç€é©´å”‡ä¸å¯¹é©¬å˜´çš„æ—§å¯¹è¯
                reset_chat_history(target_address)
                
                # --- æ­¥éª¤ 1: è·å–äº¤æ˜“æ‘˜è¦ ---
                progress_bar.progress(10, text="ğŸ“¡ æ­£åœ¨æ‰«æé“¾ä¸Šæ•°æ® (OKX API)...")
                raw_summary = get_transactions_by_address(target_address, target_chain, tx_limit)
                
                if not raw_summary:
                    st.error("æœªæ‰¾åˆ°è¯¥åœ°å€çš„äº¤æ˜“è®°å½•ã€‚è¯·ç¡®è®¤åœ°å€å’Œé“¾é€‰æ‹©æ­£ç¡®ã€‚")
                    if debug_mode:
                        st.warning("è°ƒè¯•ä¿¡æ¯ï¼šOKX API å¯èƒ½è¿”å›äº†é”™è¯¯æˆ–è¢«é™æµï¼ˆStreamlit éƒ¨ç½²ç¯å¢ƒå¸¸è§ï¼‰ã€‚")
                        st.code(json.dumps(getattr(okx_api_client, "LAST_TX_BY_ADDRESS_META", {}), ensure_ascii=False, indent=2))
                    st.stop()
                    
                tx_info_list = extract_tx_info_from_summary(raw_summary)
                
                # å»é‡
                unique_tx_hashes = set()
                unique_tx_info = []
                for tx in tx_info_list:
                    if tx['txHash'] not in unique_tx_hashes:
                        unique_tx_hashes.add(tx['txHash'])
                        unique_tx_info.append(tx)
                
                st.write(f"âœ… å‘ç° {len(unique_tx_info)} æ¡æœ€è¿‘äº¤æ˜“")
                
                # --- æ­¥éª¤ 2: ç¼“å­˜æ£€æŸ¥ä¸è¯¦æƒ…è·å– ---
                progress_bar.progress(30, text="ğŸ” æ­£åœ¨è·å–äº¤æ˜“æ·±åº¦è¯¦æƒ…...")
                
                hashes_to_check = [tx['txHash'] for tx in unique_tx_info]
                cached_data = get_transaction_details_by_hashes(hashes_to_check)
                
                all_details_raw = [item['detail'] for item in cached_data.values()]
                to_fetch = [tx for tx in unique_tx_info if tx['txHash'] not in cached_data]
                
                if to_fetch:
                    fetch_ph = st.empty()
                    for i, tx in enumerate(to_fetch):
                        fetch_ph.write(f"æ­£åœ¨ä¸‹è½½äº¤æ˜“è¯¦æƒ… ({i+1}/{len(to_fetch)}): {tx['txHash'][:10]}...")
                        try:
                            detail = get_transaction_detail_by_hash(tx['chainIndex'], tx['txHash'])
                            if detail:
                                all_details_raw.extend(detail)
                                for d in detail:
                                    add_transaction_detail(d['txhash'], d['chainIndex'], target_address, d)
                        except Exception as e:
                            st.warning(f"è·å–äº¤æ˜“ {tx['txHash']} å¤±è´¥: {e}")
                        time.sleep(1.0)
                    fetch_ph.empty()
                
                # --- æ­¥éª¤ 3: æ•°æ®æ¸…æ´—ä¸æ ‡ç­¾è·å– ---
                progress_bar.progress(50, text="ğŸ·ï¸ æ­£åœ¨è¯†åˆ«åœ°å€èº«ä»½ (Arkham Intelligence)...")
                processed_data = process_and_clean_details(all_details_raw, target_address)
                
                # æ”¶é›†åœ°å€
                all_addrs = set()
                for tx in processed_data:
                    all_addrs.add(tx['from']['address'])
                    all_addrs.add(tx['to']['address'])
                all_addrs.discard(None)
                
                # è·å–æ ‡ç­¾
                cached_labels = get_labels_by_addresses(list(all_addrs))
                new_addrs = [a for a in list(all_addrs) if a.lower() not in cached_labels]
                
                arkham_data = cached_labels
                if new_addrs:
                    st.write(f"æ­£åœ¨ä¸º {len(new_addrs)} ä¸ªæ–°åœ°å€è·å–èº«ä»½æ ‡ç­¾...")
                    new_labels = get_arkham_intelligence(new_addrs)
                    if new_labels:
                        add_labels(new_labels)
                        arkham_data.update({k.lower(): v for k, v in new_labels.items()})
                
                # æ³¨å…¥æ ‡ç­¾
                for tx in processed_data:
                    for key in ['from', 'to']:
                        addr = tx[key].get('address')
                        if addr and isinstance(addr, str) and addr.lower() in arkham_data:
                             tx[key]['addressInfo'] = arkham_data[addr.lower()]

                # --- æ­¥éª¤ 4: AI åˆ†æ ---
                progress_bar.progress(70, text="ğŸ¤– AI ä¾¦æ¢æ­£åœ¨åˆ†ææ¯ä¸€ç¬”äº¤æ˜“ (Analysis by Gemini 3)...")
                
                txs_to_analyze = []
                for tx in processed_data:
                    if 'ai_analysis' not in tx:
                        if tx['txhash'] in cached_data and cached_data[tx['txhash']].get('analysis'):
                            tx['ai_analysis'] = cached_data[tx['txhash']]['analysis']
                        else:
                            txs_to_analyze.append(tx)
                
                if txs_to_analyze:
                    ai_ph = st.empty()
                    completed_count = 0
                    with ThreadPoolExecutor(max_workers=5) as executor:
                        future_to_tx = {executor.submit(analyze_transaction, tx): tx for tx in txs_to_analyze}
                        for future in as_completed(future_to_tx):
                            tx = future_to_tx[future]
                            try:
                                res = future.result()
                                analysis_text = res.get('analysis', 'Analysis failed')
                                tx['ai_analysis'] = analysis_text
                                update_ai_analysis(tx['txhash'], analysis_text)
                            except Exception as e:
                                tx['ai_analysis'] = f"Error: {str(e)}"
                            
                            completed_count += 1
                            ai_ph.write(f"AI åˆ†æè¿›åº¦: {completed_count}/{len(txs_to_analyze)}")
                    ai_ph.empty()
                
                st.session_state.processed_txs = processed_data

                # --- æ­¥éª¤ 5: ç”Ÿæˆæ€»ç»“ ---
                progress_bar.progress(90, text="ğŸ“ æ­£åœ¨æ’°å†™æœ€ç»ˆä¾¦æŸ¥æŠ¥å‘Š...")
                all_analyses = [tx.get('ai_analysis', '') for tx in processed_data if tx.get('ai_analysis')]
                
                final_report = generate_conclusion(target_address, all_analyses)
                
                # ä¿å­˜ä¸Šä¸‹æ–‡
                from db_manager import save_chat_context, setup_chat_database
                setup_chat_database(target_address)
                save_chat_context(target_address, final_report, "\n\n".join(all_analyses))
                
                # ä¿å­˜çŠ¶æ€
                st.session_state.report_content = final_report
                st.session_state.analyses_summary = "\n\n".join(all_analyses)
                st.session_state.analysis_done = True
                st.session_state.current_address = target_address
                st.session_state.messages = [{"role": "assistant", "content": "ğŸ•µï¸â€â™‚ï¸ æŠ¥å‘Šå·²ç”Ÿæˆï¼å…³äºè¿™ä½ç”¨æˆ·çš„è¡Œä¸ºã€åŠ¨æœºæˆ–é£é™©ï¼Œæ‚¨æœ‰ä»€ä¹ˆæƒ³é—®çš„å—ï¼Ÿ"}]
                
                progress_bar.progress(100, text="åˆ†æå®Œæˆï¼")
                time.sleep(1)
                status_container.empty()
                st.rerun()
                
            except Exception as e:
                st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                st.exception(e)

# ========== ç»“æœå±•ç¤ºåŒº (åˆ†æå®Œæˆåæ˜¾ç¤º) ==========
if st.session_state.analysis_done:
    
    # 1. æŠ¥å‘ŠåŒºåŸŸ
    with st.expander("ğŸ“ æ·±åº¦ç”»åƒæŠ¥å‘Š (ç‚¹å‡»æ”¶èµ·)", expanded=True):
        st.markdown('<div class="highlight-box">ğŸ’¡ <b>AI æ ¸å¿ƒå‘ç°</b>ï¼šä»¥ä¸‹æ˜¯åŸºäºé“¾ä¸Šè¡Œä¸ºç”Ÿæˆçš„æ·±åº¦ç”»åƒã€‚</div>', unsafe_allow_html=True)
        st.markdown(st.session_state.report_content)
    
    # 2. èŠå¤©åŒºåŸŸ
    st.divider()
    st.subheader("ğŸ’¬ é“¾ä¸Šä¾¦æ¢åŠ©æ‰‹")
    st.caption("æ‚¨å¯ä»¥åƒèŠå¤©ä¸€æ ·è¿½é—®æ›´å¤šç»†èŠ‚ï¼Œä¾‹å¦‚ï¼šâ€œä»–æœ€è¿‘ä¸€ç¬”å¤§é¢äº¤æ˜“æ˜¯åœ¨åšä»€ä¹ˆï¼Ÿâ€")

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("é—®æˆ‘ä»»ä½•é—®é¢˜..."):
        from db_manager import save_chat_message
        save_chat_message(st.session_state.current_address, 'user', prompt)
        
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("ğŸ¤” æ­£åœ¨æ£€ç´¢é“¾ä¸Šè¯æ®...")
            
            try:
                response = chat_with_report(
                    st.session_state.current_address,
                    st.session_state.report_content,
                    st.session_state.analyses_summary,
                    [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages[:-1]],
                    prompt
                )
                message_placeholder.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                save_chat_message(st.session_state.current_address, 'assistant', response)
                
            except Exception as e:
                error_msg = f"å¯¹è¯å‡ºé”™: {str(e)}"
                message_placeholder.error(error_msg)

    # 3. åŸå§‹æ•°æ®åŒºåŸŸ
    st.divider()
    if st.session_state.processed_txs:
        with st.expander("ğŸ“Š æŸ¥çœ‹åŸå§‹äº¤æ˜“æ•°æ® (ç‚¹å‡»å±•å¼€)"):
            st.caption("è¿™é‡Œå±•ç¤ºäº†æ‰€æœ‰ç”¨äºåˆ†æçš„åŸå§‹äº¤æ˜“è®°å½•ã€‚")
            
            simple_data = []
            for tx in st.session_state.processed_txs:
                simple_data.append({
                    "æ—¶é—´": tx.get('time'),
                    "Hash": tx.get('txhash'),
                    "ç±»å‹": "ç”¨æˆ·å‘èµ·" if tx.get('isUserInitiated') else "è¢«åŠ¨äº¤äº’",
                    "AIæ‘˜è¦": tx.get('ai_analysis', '')[:50] + "..." if tx.get('ai_analysis') else "æ— "
                })
            df = pd.DataFrame(simple_data)
            st.dataframe(df, use_container_width=True)
            
            st.markdown("#### ğŸ” é€ç¬”äº¤æ˜“ JSON è¯¦æƒ…")
            for tx in st.session_state.processed_txs:
                tx_title = f"{tx.get('time')} | {tx.get('txhash')[:8]}... | {tx.get('ai_analysis', '')[:20]}..."
                with st.expander(tx_title):
                    st.json(tx)
                    if tx.get('ai_analysis'):
                        st.info(f"**AI å®Œæ•´åˆ†æ:**\n\n{tx['ai_analysis']}")
    else:
        with st.expander("ğŸ“Š åŸå§‹äº¤æ˜“æ•°æ®"):
            st.caption("âš ï¸ æ³¨æ„ï¼šä»å†å²æ¡£æ¡ˆæ¢å¤æ—¶ï¼Œæš‚ä¸å±•ç¤ºåŸå§‹äº¤æ˜“è¯¦æƒ…ï¼Œä»…ä¿ç•™åˆ†ææŠ¥å‘Šå’Œ AI æ‘˜è¦ã€‚")
