import streamlit as st
import pandas as pd
import json
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed

# å¯¼å…¥ç°æœ‰åç«¯æ¨¡å—
import okx_api_client
import ai_client
import arkham_client
import ai_conclusion
from okx_api_client import get_transactions_by_address, get_transaction_detail_by_hash
from data_processor import extract_tx_info_from_summary, process_and_clean_details
from ai_client import analyze_transaction
from arkham_client import get_arkham_intelligence
from ai_conclusion import generate_conclusion, chat_with_report
from db_manager import (
    get_transaction_details_by_hashes, add_transaction_detail, 
    get_labels_by_addresses, add_labels, update_ai_analysis,
    setup_databases, list_available_chats, load_chat_session,
    reset_chat_history, save_chat_context
)

# ========== é¡µé¢é…ç½® ==========
st.set_page_config(
    page_title="AI é“¾ä¸Šä¾¦æ¢",
    page_icon="ğŸ•µï¸â€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========== å…¨å±€å¸¸é‡ï¼šé“¾é…ç½® ==========
CHAIN_MAP = {
    # EVM é“¾
    "1": "Ethereum Mainnet (ETH)",
    "56": "BNB Smart Chain (BSC)",
    "137": "Polygon Mainnet",
    "42161": "Arbitrum One",
    "10": "OP Mainnet",
    "8453": "Base",
    "59144": "Linea",
    "324": "zkSync Era",
    "43114": "Avalanche C-Chain",
    "196": "X layer",
    "1101": "Polygon zkEVM",
    "146": "Sonic",
    "130": "Uni Chain",
    "250": "Fantom Opera",
    "5000": "Mantle",
    "1030": "Conflux eSpace",
    "1088": "Metis Andromeda",
    "4200": "Merlin Chain",
    "81457": "Blast",
    "169": "Manta Pacific",
    "534352": "Scroll",
    "25": "Cronos Mainnet",
    "7000": "ZetaChain",
    "9745": "Plasma",
    "143": "Monad",
    # é EVM é“¾
    "195": "Tron",
    "501": "Solana",
    "784": "SUI",
    "607": "Ton"
}

SORTED_CHAIN_IDS = ["1", "56", "137", "42161", "10", "195", "501"] + sorted(
    [k for k in CHAIN_MAP.keys() if k not in ["1", "56", "137", "42161", "10", "195", "501"]],
    key=lambda x: CHAIN_MAP[x]
)

# ========== CSS ç¾åŒ– ==========
st.markdown("""
<style>
    .report-text {
        font-family: 'Helvetica Neue', sans-serif;
        line-height: 1.6;
        color: #e0e0e0;
    }
    .stButton>button {
        width: 100%;
        border-radius: 20px;
        background-color: #FF4B4B;
        color: white;
    }
    .highlight-box {
        padding: 20px;
        background-color: #262730;
        border-radius: 10px;
        border-left: 5px solid #FF4B4B;
        margin-bottom: 20px;
    }
    .stChatInput {
        padding-bottom: 20px;
    }
</style>
""", unsafe_allow_html=True)

# ========== é…ç½®éªŒè¯ ==========
# æ‰€æœ‰ API Key ç°åœ¨éƒ½ä» .streamlit/secrets.toml è¯»å–
# å„æ¨¡å—ä¼šè‡ªåŠ¨ä» st.secrets è¯»å–é…ç½®ï¼Œè¿™é‡Œåªåšç®€å•çš„éªŒè¯æç¤º
try:
    required_keys = ["OPENROUTER_API_KEY", "OKX_API_KEY", "OKX_SECRET_KEY", "OKX_PASSPHRASE", "APIFY_API_TOKEN"]
    missing_keys = [key for key in required_keys if key not in st.secrets]
    if missing_keys:
        st.warning(f"âš ï¸ ç¼ºå°‘å¿…è¦çš„é…ç½®é¡¹: {', '.join(missing_keys)}ã€‚è¯·æ£€æŸ¥ .streamlit/secrets.toml æ–‡ä»¶ã€‚")
except FileNotFoundError:
    st.error("âŒ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼è¯·åˆ›å»º .streamlit/secrets.toml å¹¶å¡«å…¥ API Keyã€‚")

# ========== Session State åˆå§‹åŒ– ==========
if "messages" not in st.session_state:
    st.session_state.messages = []
if "analysis_done" not in st.session_state:
    st.session_state.analysis_done = False
if "report_content" not in st.session_state:
    st.session_state.report_content = ""
if "analyses_summary" not in st.session_state:
    st.session_state.analyses_summary = ""
if "processed_txs" not in st.session_state:
    st.session_state.processed_txs = []
if "current_address" not in st.session_state:
    st.session_state.current_address = ""

# åˆå§‹åŒ–æ•°æ®åº“ï¼ˆç¡®ä¿ç›®å½•å­˜åœ¨ï¼‰
setup_databases()

# ========== ä¾§è¾¹æ  ==========
with st.sidebar:
    st.title("ğŸ•µï¸â€â™‚ï¸ é…ç½®ä¸­å¿ƒ")
    
    # --- å†å²è®°å½•åŠŸèƒ½ ---
    st.markdown("### ğŸ“‚ å†å²æ¡£æ¡ˆ")
    available_chats = list_available_chats()
    
    # å¢åŠ ä¸€ä¸ª "è¯·é€‰æ‹©" çš„é»˜è®¤é€‰é¡¹
    history_options = ["è¯·é€‰æ‹©..."] + available_chats
    
    selected_history = st.selectbox(
        "æ¢å¤ä¹‹å‰çš„è°ƒæŸ¥",
        options=history_options,
        index=0,
        help="é€‰æ‹©ä¸€ä¸ªåœ°å€ä»¥æ¢å¤ä¹‹å‰çš„åˆ†ææŠ¥å‘Šå’Œå¯¹è¯è®°å½•"
    )
    
    # å¦‚æœç”¨æˆ·é€‰æ‹©äº†æŸä¸ªå†å²è®°å½•ï¼Œä¸”è·Ÿå½“å‰æ˜¾ç¤ºçš„ä¸ä»…ä»…æ˜¯åŒä¸€ä¸ª
    if selected_history != "è¯·é€‰æ‹©..." and selected_history != st.session_state.current_address:
        if st.button("ğŸ“¥ åŠ è½½æ¡£æ¡ˆ"):
            try:
                with st.spinner(f"æ­£åœ¨è¯»å– {selected_history} çš„æ¡£æ¡ˆ..."):
                    report, analyses_summary, history = load_chat_session(selected_history)
                    
                    # æ¢å¤çŠ¶æ€
                    st.session_state.report_content = report
                    st.session_state.analyses_summary = analyses_summary
                    st.session_state.current_address = selected_history
                    st.session_state.analysis_done = True
                    st.session_state.processed_txs = [] # å†å²è®°å½•æš‚ä¸æ¢å¤åŸå§‹äº¤æ˜“è¯¦æƒ…
                    
                    # æ¢å¤å¯¹è¯å†å²
                    restored_msgs = []
                    for msg in history:
                        role = "assistant" if msg['role'] == "assistant" else "user"
                        restored_msgs.append({"role": role, "content": msg['content']})
                    
                    st.session_state.messages = restored_msgs
                    
                    # å¦‚æœæ²¡æœ‰å†å²æ¶ˆæ¯ï¼Œæ·»åŠ é»˜è®¤æ¬¢è¿è¯­
                    if not st.session_state.messages:
                         st.session_state.messages = [{"role": "assistant", "content": "å†å²æ¡£æ¡ˆåŠ è½½å®Œæ¯•ã€‚æ‚¨å¯ä»¥ç»§ç»­å¯¹è¯¥åœ°å€è¿›è¡Œæé—®ã€‚"}]
                    
                    st.success("æ¡£æ¡ˆåŠ è½½æˆåŠŸï¼")
                    time.sleep(0.5)
                    st.rerun()
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {str(e)}")

    st.markdown("---")
    
    # --- æ–°åˆ†æé…ç½® ---
    st.markdown("### ğŸ¯ æ–°ä»»åŠ¡è®¾ç½®")
    
    target_chain = st.selectbox(
        "é€‰æ‹©åŒºå—é“¾",
        options=SORTED_CHAIN_IDS,
        format_func=lambda x: CHAIN_MAP.get(x, f"Unknown ({x})")
    )
    
    tx_limit = st.slider("åˆ†æäº¤æ˜“æ•°é‡", min_value=5, max_value=50, value=10, step=5)
    
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰ä¼šè¯"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# ========== ä¸»ç•Œé¢ ==========
st.title("AI é“¾ä¸Šè¡Œä¸ºåˆ†æå™¨")

# åœ°å€è¾“å…¥åŒº
if not st.session_state.analysis_done:
    st.markdown("è¾“å…¥ä»»ä½•é’±åŒ…åœ°å€ï¼ŒAI å°†ä¸ºæ‚¨ç”Ÿæˆæ·±åº¦è¡Œä¸ºç”»åƒã€èµ„é‡‘æµå‘åˆ†æä»¥åŠé£é™©è¯„ä¼°ã€‚")
    col1, col2 = st.columns([3, 1])
    with col1:
        target_address = st.text_input("é’±åŒ…åœ°å€", placeholder="ä¾‹å¦‚: 0x1234...", key="addr_input")
    with col2:
        st.write("") 
        st.write("")
        start_btn = st.button("ğŸš€ å¼€å§‹ä¾¦æŸ¥")
else:
    st.caption(f"å½“å‰è°ƒæŸ¥ç›®æ ‡: `{st.session_state.current_address}`")
    if st.button("ğŸ” è°ƒæŸ¥æ–°åœ°å€"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()
    start_btn = False

# ========== æ ¸å¿ƒåˆ†æé€»è¾‘ ==========
if start_btn and target_address:
    if len(target_address) < 10:
        st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„é’±åŒ…åœ°å€ï¼")
    else:
        status_container = st.container()
        progress_bar = st.progress(0)
        
        with status_container:
            st.info(f"æ­£åœ¨å¯åŠ¨åˆ†æå¼•æ“... ç›®æ ‡: {target_address} ({CHAIN_MAP.get(target_chain)})")
            
            try:
                # å…³é”®ä¿®å¤ï¼šå¦‚æœæ˜¯æ–°åˆ†æï¼Œå…ˆæ¸…ç©ºè¯¥åœ°å€çš„æ—§èŠå¤©è®°å½•
                # é¿å…æ–°æŠ¥å‘Šç”Ÿæˆåï¼Œä¸‹é¢è¿˜æŒ‚ç€é©´å”‡ä¸å¯¹é©¬å˜´çš„æ—§å¯¹è¯
                reset_chat_history(target_address)
                
                # --- æ­¥éª¤ 1: è·å–äº¤æ˜“æ‘˜è¦ ---
                progress_bar.progress(10, text="ğŸ“¡ æ­£åœ¨æ‰«æé“¾ä¸Šæ•°æ® (OKX API)...")
                raw_summary = get_transactions_by_address(target_address, target_chain, tx_limit)
                
                if not raw_summary:
                    st.error("æœªæ‰¾åˆ°è¯¥åœ°å€çš„äº¤æ˜“è®°å½•ã€‚è¯·ç¡®è®¤åœ°å€å’Œé“¾é€‰æ‹©æ­£ç¡®ã€‚")
                    st.stop()
                    
                tx_info_list = extract_tx_info_from_summary(raw_summary)
                
                # å»é‡
                unique_tx_hashes = set()
                unique_tx_info = []
                for tx in tx_info_list:
                    if tx['txHash'] not in unique_tx_hashes:
                        unique_tx_hashes.add(tx['txHash'])
                        unique_tx_info.append(tx)
                
                st.write(f"âœ… å‘ç° {len(unique_tx_info)} æ¡æœ€è¿‘äº¤æ˜“")
                
                # --- æ­¥éª¤ 2: ç¼“å­˜æ£€æŸ¥ä¸è¯¦æƒ…è·å– ---
                progress_bar.progress(30, text="ğŸ” æ­£åœ¨è·å–äº¤æ˜“æ·±åº¦è¯¦æƒ…...")
                
                hashes_to_check = [tx['txHash'] for tx in unique_tx_info]
                cached_data = get_transaction_details_by_hashes(hashes_to_check)
                
                all_details_raw = [item['detail'] for item in cached_data.values()]
                to_fetch = [tx for tx in unique_tx_info if tx['txHash'] not in cached_data]
                
                if to_fetch:
                    fetch_ph = st.empty()
                    for i, tx in enumerate(to_fetch):
                        fetch_ph.write(f"æ­£åœ¨ä¸‹è½½äº¤æ˜“è¯¦æƒ… ({i+1}/{len(to_fetch)}): {tx['txHash'][:10]}...")
                        try:
                            detail = get_transaction_detail_by_hash(tx['chainIndex'], tx['txHash'])
                            if detail:
                                all_details_raw.extend(detail)
                                for d in detail:
                                    add_transaction_detail(d['txhash'], d['chainIndex'], target_address, d)
                        except Exception as e:
                            st.warning(f"è·å–äº¤æ˜“ {tx['txHash']} å¤±è´¥: {e}")
                        time.sleep(1.1)  # ä¸ core_logic.py ä¿æŒä¸€è‡´ï¼Œé¿å…APIé™æµ
                    fetch_ph.empty()
                
                # --- æ­¥éª¤ 3: æ•°æ®æ¸…æ´—ä¸æ ‡ç­¾è·å– ---
                progress_bar.progress(50, text="ğŸ·ï¸ æ­£åœ¨è¯†åˆ«åœ°å€èº«ä»½ (Arkham Intelligence)...")
                processed_data = process_and_clean_details(all_details_raw, target_address)
                # å°†å¤„ç†åçš„æ•°æ®è½¬æ¢ä¸ºå­—å…¸ï¼Œä»¥äº¤æ˜“å“ˆå¸Œä¸ºé”®ï¼Œæ–¹ä¾¿åç»­æŸ¥æ‰¾
                processed_data_map = {tx['txhash']: tx for tx in processed_data}
                
                # è¾…åŠ©å‡½æ•°ï¼šä»å­—æ®µä¸­æå–åœ°å€
                # å› ä¸ºåœ°å€å¯èƒ½ä»¥å­—ç¬¦ä¸²æˆ–å­—å…¸å½¢å¼å­˜å‚¨ï¼Œéœ€è¦ç»Ÿä¸€å¤„ç†
                def get_address_from_field(field_value):
                    """ä»å­—æ®µå€¼ä¸­æå–åœ°å€ï¼Œæ”¯æŒå­—ç¬¦ä¸²å’Œå­—å…¸ä¸¤ç§æ ¼å¼"""
                    if isinstance(field_value, dict):
                        return field_value.get('address')
                    elif isinstance(field_value, str):
                        return field_value
                    return None
                
                # æ”¶é›†åœ°å€ï¼ˆåŒ…æ‹¬ä¸»äº¤æ˜“ã€å†…éƒ¨äº¤æ˜“ã€ä»£å¸è½¬è´¦ä¸­çš„æ‰€æœ‰åœ°å€ï¼‰
                all_addrs = set()
                for tx in processed_data:
                    # ä¸»äº¤æ˜“çš„ from/to
                    all_addrs.add(tx['from']['address'])
                    all_addrs.add(tx['to']['address'])
                    # å†…éƒ¨äº¤æ˜“ä¸­çš„åœ°å€
                    for itx in tx.get('internalTransactions', []):
                        all_addrs.add(get_address_from_field(itx.get('from')))
                        all_addrs.add(get_address_from_field(itx.get('to')))
                    # ä»£å¸è½¬è´¦ä¸­çš„åœ°å€
                    for ttx in tx.get('tokenTransfers', []):
                        all_addrs.add(get_address_from_field(ttx.get('from')))
                        all_addrs.add(get_address_from_field(ttx.get('to')))
                # ç§»é™¤ç©ºå€¼
                all_addrs.discard(None)
                all_addrs.discard("")
                
                # è·å–æ ‡ç­¾
                cached_labels = get_labels_by_addresses(list(all_addrs))
                new_addrs = [a for a in list(all_addrs) if a.lower() not in cached_labels]
                
                arkham_data = cached_labels
                if new_addrs:
                    st.write(f"æ­£åœ¨ä¸º {len(new_addrs)} ä¸ªæ–°åœ°å€è·å–èº«ä»½æ ‡ç­¾...")
                    new_labels = get_arkham_intelligence(new_addrs)
                    if new_labels:
                        add_labels(new_labels)
                        arkham_data.update({k.lower(): v for k, v in new_labels.items()})
                
                # æ³¨å…¥æ ‡ç­¾ï¼ˆä¸»äº¤æ˜“ + å†…éƒ¨äº¤æ˜“ + ä»£å¸è½¬è´¦ï¼‰
                def enrich_address_field(target_dict, address_key):
                    """
                    ä¸ºåœ°å€å­—æ®µæ·»åŠ æ ‡ç­¾ä¿¡æ¯
                    
                    å‚æ•°:
                        target_dict: åŒ…å«åœ°å€å­—æ®µçš„å­—å…¸ï¼ˆä¾‹å¦‚ï¼štx, itx, ttxï¼‰
                        address_key: åœ°å€å­—æ®µçš„é”®åï¼ˆ'from' æˆ– 'to'ï¼‰
                    """
                    field_value = target_dict.get(address_key)
                    addr_str = get_address_from_field(field_value)
                    
                    # å¦‚æœåœ°å€åœ¨æ ‡ç­¾æ•°æ®ä¸­ï¼Œæ·»åŠ æ ‡ç­¾ä¿¡æ¯
                    if addr_str and addr_str.lower() in arkham_data:
                        # å¦‚æœåœ°å€æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œå…ˆè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                        if isinstance(field_value, str):
                            target_dict[address_key] = {"address": field_value}
                        
                        # æ·»åŠ åœ°å€ä¿¡æ¯ï¼ˆå¦‚æœè¿˜æ²¡æœ‰æ·»åŠ è¿‡ï¼‰
                        if "addressInfo" not in target_dict[address_key]:
                             target_dict[address_key]['addressInfo'] = arkham_data[addr_str.lower()]
                
                for tx in processed_data:
                    # ä¸ºä¸»äº¤æ˜“çš„from/toæ·»åŠ æ ‡ç­¾
                    enrich_address_field(tx, 'from')
                    enrich_address_field(tx, 'to')
                    # ä¸ºå†…éƒ¨äº¤æ˜“çš„from/toæ·»åŠ æ ‡ç­¾
                    for itx in tx.get('internalTransactions', []):
                        enrich_address_field(itx, 'from')
                        enrich_address_field(itx, 'to')
                    # ä¸ºä»£å¸è½¬è´¦çš„from/toæ·»åŠ æ ‡ç­¾
                    for ttx in tx.get('tokenTransfers', []):
                        enrich_address_field(ttx, 'from')
                        enrich_address_field(ttx, 'to')

                # --- æ­¥éª¤ 4: AI åˆ†æ ---
                progress_bar.progress(70, text="ğŸ¤– AI ä¾¦æ¢æ­£åœ¨åˆ†ææ¯ä¸€ç¬”äº¤æ˜“ (Analysis by Gemini 3)...")
                
                # æ£€æŸ¥å“ªäº›äº¤æ˜“å·²ç»æœ‰AIåˆ†æç»“æœï¼ˆä»æ•°æ®åº“ç¼“å­˜ä¸­ï¼‰
                txs_to_analyze = []
                for tx_hash, tx_data in processed_data_map.items():
                    if tx_hash in cached_data and cached_data[tx_hash].get('analysis'):
                        # å¦‚æœå·²æœ‰åˆ†æç»“æœï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜
                        tx_data['ai_analysis'] = cached_data[tx_hash]['analysis']
                    else:
                        # å¦‚æœæ²¡æœ‰åˆ†æç»“æœï¼ŒåŠ å…¥å¾…åˆ†æåˆ—è¡¨
                        txs_to_analyze.append(tx_data)
                
                st.write(f"AIåˆ†æç¼“å­˜æ£€æŸ¥ï¼š{len(processed_data) - len(txs_to_analyze)} æ¡å·²æœ‰åˆ†æï¼Œ{len(txs_to_analyze)} æ¡éœ€è¦è¿›è¡ŒAIåˆ†æã€‚")
                
                # å¦‚æœæœ‰éœ€è¦åˆ†æçš„äº¤æ˜“ï¼Œä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
                if txs_to_analyze:
                    ai_ph = st.empty()
                    completed_count = 0
                    # åˆ›å»ºçº¿ç¨‹æ± ï¼Œæœ€å¤š10ä¸ªå¹¶å‘çº¿ç¨‹ï¼ˆä¸ core_logic.py ä¿æŒä¸€è‡´ï¼‰
                    with ThreadPoolExecutor(max_workers=10) as executor:
                        future_to_tx = {executor.submit(analyze_transaction, tx): tx for tx in txs_to_analyze}
                        for future in as_completed(future_to_tx):
                            tx = future_to_tx[future]
                            try:
                                # è·å–AIåˆ†æç»“æœï¼ˆè¿™é‡Œä¼šç­‰å¾…ä»»åŠ¡å®Œæˆï¼‰
                                ai_result = future.result()
                                analysis_text = ai_result.get('analysis', 'Analysis not available.')
                                # å°†åˆ†æç»“æœæ·»åŠ åˆ°äº¤æ˜“æ•°æ®ä¸­
                                tx['ai_analysis'] = analysis_text
                                # ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“ï¼Œä¾›ä¸‹æ¬¡ä½¿ç”¨
                                update_ai_analysis(tx['txhash'], analysis_text)
                            except Exception as exc:
                                # å¦‚æœæŸç¬”äº¤æ˜“çš„AIåˆ†æå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–äº¤æ˜“
                                st.warning(f"äº¤æ˜“ {tx.get('txhash')} åœ¨AIåˆ†æç¯èŠ‚äº§ç”Ÿé”™è¯¯: {exc}")
                                tx['ai_analysis'] = f'Failed to analyze: {str(exc)}'
                            
                            completed_count += 1
                            ai_ph.write(f"AI åˆ†æè¿›åº¦: {completed_count}/{len(txs_to_analyze)}")
                    ai_ph.empty()
                
                st.session_state.processed_txs = list(processed_data_map.values())

                # --- æ­¥éª¤ 5: ç”Ÿæˆæ€»ç»“ ---
                progress_bar.progress(90, text="ğŸ“ æ­£åœ¨æ’°å†™æœ€ç»ˆä¾¦æŸ¥æŠ¥å‘Š...")
                # æå–æ‰€æœ‰æœ‰æ•ˆçš„AIåˆ†ææ–‡æœ¬ï¼ˆä¸ core_logic.py ä¿æŒä¸€è‡´ï¼Œä½¿ç”¨ processed_data_mapï¼‰
                all_analyses = [tx.get('ai_analysis', '') for tx in processed_data_map.values() if tx.get('ai_analysis')]
                
                # åˆ›å»ºä¸“é—¨çš„æ€»ç»“ç”ŸæˆloadingåŒºåŸŸ
                summary_loading = st.empty()
                with summary_loading.container():
                    st.markdown("---")
                    st.info("""
                    **ğŸ¤– AI ä¾¦æ¢æ­£åœ¨æ·±åº¦æ€è€ƒä¸­ (Analysis by Gemini 3)......**
                    
                    **æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ï¼š**
                    - ğŸ“Š æ±‡æ€»æ‰€æœ‰äº¤æ˜“è¡Œä¸ºæ¨¡å¼
                    - ğŸ¯ æ¨æ–­ç”¨æˆ·èº«ä»½ä¸ç­–ç•¥  
                    - ğŸ’° åˆ†æèµ„é‡‘æµå‘å›¾è°±
                    - âš ï¸ è¯„ä¼°æ½œåœ¨é£é™©ç‚¹
                    
                    *Gemini 3 Pro æ­£åœ¨ç”Ÿæˆæ·±åº¦ç”»åƒæŠ¥å‘Šï¼Œè¿™å¯èƒ½éœ€è¦ 10-30 ç§’ï¼Œè¯·ç¨å€™...*
                    """)
                
                # è°ƒç”¨AIç”ŸæˆæŠ¥å‘Šï¼ˆè¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦10-30ç§’ï¼‰
                # ä½¿ç”¨spinneråŒ…è£¹ï¼Œè®©ç”¨æˆ·çŸ¥é“ç¨‹åºæ²¡æœ‰å¡æ­»
                with st.spinner("ğŸ•µï¸â€â™‚ï¸ AI æ­£åœ¨åˆ†æé“¾ä¸Šæ•°æ®ï¼Œç”Ÿæˆæ·±åº¦ç”»åƒæŠ¥å‘Š..."):
                    final_report = generate_conclusion(target_address, all_analyses)
                
                # ç”Ÿæˆå®Œæˆåï¼Œæ¸…ç©ºloadingæç¤º
                summary_loading.empty()
                
                # ä¿å­˜ä¸Šä¸‹æ–‡ï¼ˆä¸ core_logic.py ä¿æŒä¸€è‡´ï¼Œä½¿ç”¨åˆ†éš”ç¬¦è¿æ¥ï¼‰
                analyses_summary_str = "\n\n---\n\n".join(all_analyses)
                save_chat_context(target_address, final_report, analyses_summary_str)
                
                # ä¿å­˜çŠ¶æ€
                st.session_state.report_content = final_report
                st.session_state.analyses_summary = analyses_summary_str
                st.session_state.analysis_done = True
                st.session_state.current_address = target_address
                st.session_state.messages = [{"role": "assistant", "content": "ğŸ•µï¸â€â™‚ï¸ æŠ¥å‘Šå·²ç”Ÿæˆï¼å…³äºè¿™ä½ç”¨æˆ·çš„è¡Œä¸ºã€åŠ¨æœºæˆ–é£é™©ï¼Œæ‚¨æœ‰ä»€ä¹ˆæƒ³é—®çš„å—ï¼Ÿ"}]
                
                progress_bar.progress(100, text="åˆ†æå®Œæˆï¼")
                time.sleep(1)
                status_container.empty()
                st.rerun()
                
            except Exception as e:
                st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                st.exception(e)

# ========== ç»“æœå±•ç¤ºåŒº (åˆ†æå®Œæˆåæ˜¾ç¤º) ==========
if st.session_state.analysis_done:
    
    # 1. æŠ¥å‘ŠåŒºåŸŸ
    with st.expander("ğŸ“ æ·±åº¦ç”»åƒæŠ¥å‘Š (ç‚¹å‡»æ”¶èµ·)", expanded=True):
        st.markdown('<div class="highlight-box">ğŸ’¡ <b>AI æ ¸å¿ƒå‘ç°</b>ï¼šä»¥ä¸‹æ˜¯åŸºäºé“¾ä¸Šè¡Œä¸ºç”Ÿæˆçš„æ·±åº¦ç”»åƒã€‚</div>', unsafe_allow_html=True)
        st.markdown(st.session_state.report_content)
    
    # 2. èŠå¤©åŒºåŸŸ
    st.divider()
    st.subheader("ğŸ’¬ é“¾ä¸Šä¾¦æ¢åŠ©æ‰‹")
    st.caption("æ‚¨å¯ä»¥åƒèŠå¤©ä¸€æ ·è¿½é—®æ›´å¤šç»†èŠ‚ï¼Œä¾‹å¦‚ï¼šâ€œä»–æœ€è¿‘ä¸€ç¬”å¤§é¢äº¤æ˜“æ˜¯åœ¨åšä»€ä¹ˆï¼Ÿâ€")

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("é—®æˆ‘ä»»ä½•é—®é¢˜..."):
        from db_manager import save_chat_message
        save_chat_message(st.session_state.current_address, 'user', prompt)
        
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("ğŸ¤” æ­£åœ¨æ£€ç´¢é“¾ä¸Šè¯æ®...")
            
            try:
                response = chat_with_report(
                    st.session_state.current_address,
                    st.session_state.report_content,
                    st.session_state.analyses_summary,
                    [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages[:-1]],
                    prompt
                )
                message_placeholder.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                save_chat_message(st.session_state.current_address, 'assistant', response)
                
            except Exception as e:
                error_msg = f"å¯¹è¯å‡ºé”™: {str(e)}"
                message_placeholder.error(error_msg)

    # 3. åŸå§‹æ•°æ®åŒºåŸŸ
    st.divider()
    if st.session_state.processed_txs:
        with st.expander("ğŸ“Š æŸ¥çœ‹åŸå§‹äº¤æ˜“æ•°æ® (ç‚¹å‡»å±•å¼€)"):
            st.caption("è¿™é‡Œå±•ç¤ºäº†æ‰€æœ‰ç”¨äºåˆ†æçš„åŸå§‹äº¤æ˜“è®°å½•ã€‚")
            
            simple_data = []
            for tx in st.session_state.processed_txs:
                simple_data.append({
                    "æ—¶é—´": tx.get('time'),
                    "Hash": tx.get('txhash'),
                    "ç±»å‹": "ç”¨æˆ·å‘èµ·" if tx.get('isUserInitiated') else "è¢«åŠ¨äº¤äº’",
                    "AIæ‘˜è¦": tx.get('ai_analysis', '')[:50] + "..." if tx.get('ai_analysis') else "æ— "
                })
            df = pd.DataFrame(simple_data)
            st.dataframe(df, use_container_width=True)
            
            st.markdown("#### ğŸ” é€ç¬”äº¤æ˜“ JSON è¯¦æƒ…")
            for tx in st.session_state.processed_txs:
                tx_title = f"{tx.get('time')} | {tx.get('txhash')[:8]}... | {tx.get('ai_analysis', '')[:20]}..."
                with st.expander(tx_title):
                    st.json(tx)
                    if tx.get('ai_analysis'):
                        st.info(f"**AI å®Œæ•´åˆ†æ:**\n\n{tx['ai_analysis']}")
    else:
        with st.expander("ğŸ“Š åŸå§‹äº¤æ˜“æ•°æ®"):
            st.caption("âš ï¸ æ³¨æ„ï¼šä»å†å²æ¡£æ¡ˆæ¢å¤æ—¶ï¼Œæš‚ä¸å±•ç¤ºåŸå§‹äº¤æ˜“è¯¦æƒ…ï¼Œä»…ä¿ç•™åˆ†ææŠ¥å‘Šå’Œ AI æ‘˜è¦ã€‚")
